{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = ['Jane_Austen.txt' , 'Franz_Kafka.txt' , 'Charles_Dickens.txt' , 'Emily_Bronte.txt']\n",
    "file_name = [\"Three plays for Puritans, The devil's disciple, Cæsar and Cleopatra, & Captain Brassbound's conversion_djvu.txt\",\n",
    "\"Widowers' housesa play_djvu.txt\",\"Arms and the man; an anti-romantic comedy in three acts_djvu.txt\",\n",
    "\"Back to Methuselah. A metabiological pentateuch_djvu.txt\",\n",
    "\"Bernard Shaw on modern typography_djvu.txt\",\n",
    "\"Candida a pleasant play_djvu.txt\",\n",
    "\"Charles_Dickens.txt\",\n",
    "\"Dramatic opinions and essays_djvu.txt\",\n",
    "\"D:\\RUSHIL - 2021-24\\Programming 2022-23\\ML-and-AI-Practice\\Project WiLLM\\Emily_Bronte.txt\",\n",
    "\"D:\\RUSHIL - 2021-24\\Programming 2022-23\\ML-and-AI-Practice\\Project WiLLM\\Fabianism and the empire ,a manifesto by the Fabian society_djvu.txt\",\n",
    "\"D:\\RUSHIL - 2021-24\\Programming 2022-23\\ML-and-AI-Practice\\Project WiLLM\\Franz_Kafka.txt\",\n",
    "\"D:\\RUSHIL - 2021-24\\Programming 2022-23\\ML-and-AI-Practice\\Project WiLLM\\Jane_Austen.txt\",\n",
    "\"D:\\RUSHIL - 2021-24\\Programming 2022-23\\ML-and-AI-Practice\\Project WiLLM\\Man and superman; a comedy and a philosophy_djvu.txt\",\n",
    "\"D:\\RUSHIL - 2021-24\\Programming 2022-23\\ML-and-AI-Practice\\Project WiLLM\\Misalliance, The dark lady of the Sonnets, and Fanny's first play_djvu.txt\",\n",
    "\"D:\\RUSHIL - 2021-24\\Programming 2022-23\\ML-and-AI-Practice\\Project WiLLM\\Mrs. Warren's profession ; a play in four act_djvu.txt\",\n",
    "\"D:\\RUSHIL - 2021-24\\Programming 2022-23\\ML-and-AI-Practice\\Project WiLLM\\Pygmalion  a play in five acts,_djvu.txt\",\n",
    "\"D:\\RUSHIL - 2021-24\\Programming 2022-23\\ML-and-AI-Practice\\Project WiLLM\\Ruskin's politics_djvu.txt\",\n",
    "\"D:\\RUSHIL - 2021-24\\Programming 2022-23\\ML-and-AI-Practice\\Project WiLLM\\Socialism and superior brains , a reply to Mr. Mallock_djvu.txt\",\n",
    "\"D:\\RUSHIL - 2021-24\\Programming 2022-23\\ML-and-AI-Practice\\Project WiLLM\\The doctor's dilemma, Getting married, and The shewing-up of Blanco Posnet_djvu.txt\",\n",
    "\"D:\\RUSHIL - 2021-24\\Programming 2022-23\\ML-and-AI-Practice\\Project WiLLM\\The doctor's dilemma; a tragedy_djvu.txt\",\n",
    "\"D:\\RUSHIL - 2021-24\\Programming 2022-23\\ML-and-AI-Practice\\Project WiLLM\\The impossibilities of anarchism_djvu.txt\",\n",
    "\"D:\\RUSHIL - 2021-24\\Programming 2022-23\\ML-and-AI-Practice\\Project WiLLM\\The perfect Wagnerite  a commentary on the Niblung's Ring_djvu.txt\",\n",
    "\"D:\\RUSHIL - 2021-24\\Programming 2022-23\\ML-and-AI-Practice\\Project WiLLM\\The quintessence of Ibsenism_djvu.txt\",\n",
    "\"D:\\RUSHIL - 2021-24\\Programming 2022-23\\ML-and-AI-Practice\\Project WiLLM\\The sanity of art_djvu.txt\",\n",
    "\"D:\\RUSHIL - 2021-24\\Programming 2022-23\\ML-and-AI-Practice\\Project WiLLM\\The wisdom of Bernard Shaw;_djvu.txt\",\n",
    "\"D:\\RUSHIL - 2021-24\\Programming 2022-23\\ML-and-AI-Practice\\Project WiLLM\\Thoreau.txt\"]\n",
    "text = str()\n",
    "\"\"\"for fi in file_name:\n",
    "    with open(f'Dssataset/{fi}' , 'rU' , encoding='utf-8' ,errors='ignore') as f:\n",
    "        text += f.read()\"\"\"\n",
    "with open(\"Dataset/Shakespeare.txt\" , 'r' , encoding='utf-8' ,errors='ignore') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of text in DataSet is: 5458199\n"
     ]
    }
   ],
   "source": [
    "print(f'length of text in DataSet is: {len(text)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !\"#%&'()*,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_`abcdefghijklmnopqrstuvwxyz|}~\n",
      "91\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BPE Tokenizer (Building and Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "trainer = BpeTrainer(special_tokens = [\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"])\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "files = ['Dataset/Shakespeare.txt']\n",
    "tokenizer.train(files , trainer)\n",
    "tokenizer.save('tokenizer_WiLLM.json')\n",
    "tokenizer = Tokenizer.from_file('tokenizer_WiLLM.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['He', 'llo', 'y', \"'\", 'all', 'in', 'the', 'World']\n",
      "[280, 2530, 89, 10, 167, 97, 99, 13378]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output = tokenizer.encode(\"Hello y'all in the World\")\n",
    "print(output.tokens)\n",
    "print(output.ids)\n",
    "tokenizer.decode([18655, 82, 8, 147, 93, 94, 17709])\n",
    "vocab_size = tokenizer.get_vocab_size()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Computation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1180098]) torch.int64\n",
      "tensor([  415,   101,    99, 16656,    94, 13856,  6340,  8386,   223,  7811,\n",
      "         8851,    14,   108,   101,  8386,    97, 23490,   148, 13378, 12308,\n",
      "           14, 15808,  1411,   271,   304, 12308,   115,    99, 17120,   108,\n",
      "         4529, 24992,    53,    16,  7811,  8851,  2245, 14067,   107, 15163,\n",
      "          145,   192,  1469,  8711,    97,    99,  6278,  1930, 28866, 17052,\n",
      "         4529,    13,   415, 13856,  1041,  1546, 12549,  1119, 14583,   113,\n",
      "          354,   793, 24783,  1564,  1366,   871,  1516,   347,  1046,  1499,\n",
      "         1556,   347,  1162,  1498,   325,  1558,  1541,    15,  1542,   495,\n",
      "         1557,  1515,    14,   521,  1411,   369,   325,  1518,   495,  1511,\n",
      "         1517,  1480,   347,  1561,  1562,  1550,  1547,  1560,    16,   871,\n",
      "          369,  1552,  1545,   872,  1297,   768,   876,   934,  1253,   708,\n",
      "         1505,   872,    11,    19,    12,   623,   451,  1549,   195,  1421,\n",
      "         1551,   854,  1527,    14,   369,    11,    20,    12,   623,  1469,\n",
      "          876,   195,  1525,  1544,    16,  1559,   873,  1537,  1553,   495,\n",
      "         1465,  1540,  1508,  1495,   451,  1543,  1481,   195,   451,  1555,\n",
      "         1567,    13,  7811,  8851,   101,  1453,   109,  7261,  3771,   148,\n",
      "          190, 13378, 12308,    13,    97,    99, 18250,   115,   190, 16638,\n",
      "        14607,   115,  3040,  4529,   130,   160,  4912,   130, 11106,   108,\n",
      "         5088,    16, 25149, 25063,    14,  1366,   325,  2316, 20037, 29074,\n",
      "        25531,  1723, 10066,   372, 29679,    16,    16,    16,   369, 18249,\n",
      "         1046,  1515,   347,  1046, 25082, 18095,  2094, 28926,    53,   347,\n",
      "         1366,  1093, 27558,  1340,    16,    16,    16,  8543,  1495,  1297,\n",
      "          768, 21427,   451,    13,  1465,    13, 29584,  1069,  1366, 28750,\n",
      "        25159,    16,  5550,   623, 24687, 17052,  1069, 24585,  5105, 24883,\n",
      "         4858,  1069,  1465,  2027,  5550, 21850,    14,  9222,  8543,  1495,\n",
      "          623, 27873,   316, 17052,  5290,  2800,   216,   190, 13378,   115,\n",
      "         7680,  8877, 15345, 27721, 10085, 28084, 25489,  5290,  5290, 15163,\n",
      "         5937,   646,   538,  2904,  3615, 11362,   108,   538,  6238, 26790,\n",
      "           14,  1911, 19871, 19879,  5290,    13,  1395, 15163, 19234,   153,\n",
      "          538, 24270,   115,  3843, 27099,   270,   108,  3794,  2361,    13,\n",
      "        19506,   106,  8013, 12132,  7811,  8851,   109,   947, 15163,    14,\n",
      "          108,  1726, 12484,   101, 22931,  4107,    16,   340,   963,   160,\n",
      "        19115,    16,   190, 16638, 14607,   115,  3040,  4529, 19770,    14,\n",
      "        29677,    61, 13856,     7, 16656,    62,   190, 12308,   115,    99,\n",
      "        17120, 16638, 14607,   115,  3040,  4529, 12308,   115,    99, 17120,\n",
      "          101,    65,  6282, 26844,    11, 25453,    12,   115, 13378, 12308,\n",
      "        15808,    16, 23941,   415,  6340,   354,   124, 14369, 24305,    16,\n",
      "        17378,   100, 24305,    16, 20452, 19480, 18503,  2414, 28243,    53,\n",
      "          115,   149, 17614,   947,    65,   561, 25256,   462,    14, 15666,\n",
      "         8230,    16, 17378,  1516,    53,  1951,    68,   106, 13647, 22960,\n",
      "          947,   561, 13065,  3204,    14, 15666,  6549,    65,    16, 17378,\n",
      "          339,   113,   284,   315,  1726, 12484,   999, 13378, 12308,    14,\n",
      "        15808,    16,  3498,   563,   288,   103,    19,    15, 24870,    15,\n",
      "        24832,    15, 24799,    26,   100, 17283,  5704, 26868,    34,  3506,\n",
      "          238,    16,   238,  3498,   442,   288,   149,  2286,   130,   304,\n",
      "         4529, 23490,     5,   190, 19507, 10683,  6022,   115,   167,  7811,\n",
      "         8851, 15163,   101,   103, 24168,    14,  9611, 12842,  3283,    14,\n",
      "          115,    99,  1059,   394,   115,    99, 26471,  2711,    16,    35,\n",
      "        29259,  1326, 20946,   358,  2245,   124, 12398,   130,  9559,    14,\n",
      "         8977,   108, 26928,   223,   826,   367,  1180,   109,   168,   154,\n",
      "           16,   216,   124,   918,   113,   178,    98,   233,   109,  6022,\n",
      "          821, 20761,    61, 12860, 24080,  6549,    88,    16, 24080,    62,\n",
      "         1016,  4909,  6340, 17767,    97,    99,   821,  5726,   115,    99,\n",
      "         1925,  2711,    16,  1911,   149, 21731, 17897,  1041,    65, 16059,\n",
      "           97,   117,   145, 28945,  1609,    99,  6022,    61,  7125,   109,\n",
      "         3772,   108, 27634,    62,    65,   498,   103,    99,  6340,  8974,\n",
      "          191,   178,   109,   168,    14,   214,   144,   191,  2601,   109,\n",
      "          301,    65,   561,  6401,  1041,   103,  2631,   212, 27706,   286,\n",
      "          100,   527,    16, 19506,   999,  7811,  8851,    11,   212,  3968,\n",
      "           12,   340,  8346,   999,   648,  7208, 17635,   130,  1612,   816,\n",
      "          144,  1593,    16,   190,  5376,  2149,   101,   212, 27737,  6031,\n",
      "        12469,   130,   436,   636,   117,   144,   434,   109,   947,   433,\n",
      "         7082, 17497,  2414,    14, 17603,    14,  2428,   793,    14, 26926,\n",
      "           14, 12549,  9319,  2325,   108, 26278,  8281,    14,    99, 12549,\n",
      "         2272,  5357,    14,  7308,    16,   415,  8656,   153,  5530,   101,\n",
      "          212,  2400,  7208, 21763,    16,   339,   149,  5962,   381,  6911,\n",
      "          101,  8594,  2026,  4154, 11996,   103,   212, 20831,    14,   327,\n",
      "          144,  8346,    20,  7208, 17635,   381,   816,   176,  2518,   144,\n",
      "           14,   191,   178,   109,   168,  1776,  6911, 10633,   381,  2711,\n",
      "           28,   680, 21082,   149, 17895,  2424,  4315,   271,   212,  7208,\n",
      "           16,   190, 28390,   115,  7811,  8851,   101,   109,  1078,  1812,\n",
      "         1653, 22856, 13856, 25095,   223,    99, 11856, 19876,    14, 24556,\n",
      "           16,    61,  6549,    14, 19414,    88, 16656,    14, 19414,    14,\n",
      "        19414,    31, 22856,    62,   415,   101,   621,  1053,  6970,  1612,\n",
      "          109,   212,  2400,  7208, 21763,    14,   373,   101,  6549,     8,\n",
      "          115,    99,  9510,  3884,   115, 24308, 20812,   223,    99,   215,\n",
      "          115,    99,  2518, 24556,    16,   340,   963,   160, 19115,   286,\n",
      "          309,   536,     5,   911, 19115,   354,   124,   566,   109,     6,\n",
      "         7811,  8851,    17, 17140, 24785,   108,   192,  6323, 29233,   259,\n",
      "          109,    99, 13104,  3162,   646,   223,   961, 24789, 17140,     6,\n",
      "          101, 24780, 24521, 24042, 17055,    11,  6653, 12481,    83,   109,\n",
      "          149,  2557,  1124,   988,   235,   109, 17140,    14,   351,    12,\n",
      "          296,   441,   108,   390,  6217,    14,  1016, 10733,   109,    28,\n",
      "         7811,  8851,    50,    16,    49,    16, 22218, 24373, 24358,    14,\n",
      "          398, 24374,   526,   167,   390, 17283, 10211,  2601,   149,  6717,\n",
      "           53,    16, 15265,    14, 21432,   292, 19950,   949,    28,  8900,\n",
      "           34, 12858,    16, 13943,    16, 12605,    16,  7305,    11, 18413,\n",
      "           12,  8900,    34, 24050,    11,  1258,  3506,    12,   340,   284,\n",
      "         4635,   109,  1236,   113,   176, 12484,   223, 17283,    11, 19834,\n",
      "           14, 24378,    14,  6238, 20815,    14, 29374,   398,   100, 25226,\n",
      "        10733, 17055, 23941,   339,   113,   178,    98, 24576, 17897,    11,\n",
      "          100, 23548,  5792,  1016, 24576,  5987,   109,    99,  7811,  8851,\n",
      "         2462,  7701,    28,    61,  2277, 20812,    14,   168,  1469,  1845,\n",
      "          108,  4370,   206,    16,    16,    16, 18044,    62, 21731, 25861,\n",
      "        25647,    16, 13943,    16, 12605,    16,  7305, 20955,    28,  2724,\n",
      "         6441,   248,  1278,   385,    28,   160,    34, 20955, 12788,  7082,\n",
      "           17,  7082, 19881,   100, 12788,  7082, 19882,   100, 12788, 23477,\n",
      "           61,   130,   561,  4922,    62,    61,   201,  4891,    97, 12788,\n",
      "         7082,    17, 23477,    62,   100, 12788,  7082,    17,  7427,    61,\n",
      "          947, 10482, 25752,   130,   286, 12484,    62,  9269,    61,   109])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data = torch.tensor(tokenizer.encode(text).ids , dtype = torch.long)\n",
    "print(data.shape , data.dtype)\n",
    "print(data[:1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9*len(data))\n",
    "train_data= data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[1008, 1011,   14,   43,   10,   68,  487,  219],\n",
      "        [  10,   78,   16,  696,   14,  113,  192,  109],\n",
      "        [  16,  340,  191,  967,   29,  108,  299,  144],\n",
      "        [1585,   16, 1165,   16,  252,  757,  115, 5869]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[1011,   14,   43,   10,   68,  487,  219,   16],\n",
      "        [  78,   16,  696,   14,  113,  192,  109,  563],\n",
      "        [ 340,  191,  967,   29,  108,  299,  144,  358],\n",
      "        [  16, 1165,   16,  252,  757,  115, 5869,   33]])\n",
      "----\n",
      "tensor([[1008, 1011,   14,   43,   10,   68,  487,  219],\n",
      "        [  10,   78,   16,  696,   14,  113,  192,  109],\n",
      "        [  16,  340,  191,  967,   29,  108,  299,  144],\n",
      "        [1585,   16, 1165,   16,  252,  757,  115, 5869]])\n"
     ]
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size+1]\n",
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size]\n",
    "torch.manual_seed(1337)\n",
    "batch_size = 4 # how many independent sequences will we process in parallel?\n",
    "block_size = 8 # what is the maximum context length for predictions?\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('----')\n",
    "print(xb) # our input to the transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        logits = self.token_embedding_table(idx) # (B,T,C)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 30000])\n",
      "tensor(10.6547, grad_fn=<NllLossBackward0>)\n",
      "deluge Madam awe Gon regar unspoke Pass Provide om nose mblies Stands LONG ABILITY penitent pared mote Ven Offic ribb WAT Hazard Ague requests conditions requested pleasance dropping OLYCUS Prentices loathing Beginning clod shipping sympathise Cris pestilence uish ELAND ete Aguecheek party iteth conduct gests encour Collars ist vicer veil medicine GUIDERIUS wretched Pick Pentecost Norways taxing wi merri Rochester directions deflower approbation creant worthies chim vereign Tus Question Like Chath essence scann Reserve Weed noddy Gainst scabbard Vill officers 33 fork stately beggarly divert entreaty cre itime wich ley unsway False griffin trude deemer swifter .? sith GL bick\n"
     ]
    }
   ],
   "source": [
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "print(tokenizer.decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 3600000000 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad(set_to_none\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     12\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m---> 13\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[0;32m     15\u001b[0m \u001b[39mprint\u001b[39m(loss\u001b[39m.\u001b[39mitem())\n",
      "File \u001b[1;32md:\\python\\Lib\\site-packages\\torch\\optim\\optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    277\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m                                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 280\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    281\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    283\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32md:\\python\\Lib\\site-packages\\torch\\optim\\optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> 33\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     34\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     35\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[1;32md:\\python\\Lib\\site-packages\\torch\\optim\\adamw.py:171\u001b[0m, in \u001b[0;36mAdamW.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    158\u001b[0m     beta1, beta2 \u001b[39m=\u001b[39m group[\u001b[39m\"\u001b[39m\u001b[39mbetas\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    160\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_group(\n\u001b[0;32m    161\u001b[0m         group,\n\u001b[0;32m    162\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    168\u001b[0m         state_steps,\n\u001b[0;32m    169\u001b[0m     )\n\u001b[1;32m--> 171\u001b[0m     adamw(\n\u001b[0;32m    172\u001b[0m         params_with_grad,\n\u001b[0;32m    173\u001b[0m         grads,\n\u001b[0;32m    174\u001b[0m         exp_avgs,\n\u001b[0;32m    175\u001b[0m         exp_avg_sqs,\n\u001b[0;32m    176\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    177\u001b[0m         state_steps,\n\u001b[0;32m    178\u001b[0m         amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[0;32m    179\u001b[0m         beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[0;32m    180\u001b[0m         beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[0;32m    181\u001b[0m         lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m    182\u001b[0m         weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m    183\u001b[0m         eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m    184\u001b[0m         maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m    185\u001b[0m         foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m    186\u001b[0m         capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m    187\u001b[0m         differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m    188\u001b[0m         fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m    189\u001b[0m         grad_scale\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mgrad_scale\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m    190\u001b[0m         found_inf\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfound_inf\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m    191\u001b[0m     )\n\u001b[0;32m    193\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32md:\\python\\Lib\\site-packages\\torch\\optim\\adamw.py:321\u001b[0m, in \u001b[0;36madamw\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adamw\n\u001b[1;32m--> 321\u001b[0m func(\n\u001b[0;32m    322\u001b[0m     params,\n\u001b[0;32m    323\u001b[0m     grads,\n\u001b[0;32m    324\u001b[0m     exp_avgs,\n\u001b[0;32m    325\u001b[0m     exp_avg_sqs,\n\u001b[0;32m    326\u001b[0m     max_exp_avg_sqs,\n\u001b[0;32m    327\u001b[0m     state_steps,\n\u001b[0;32m    328\u001b[0m     amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[0;32m    329\u001b[0m     beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[0;32m    330\u001b[0m     beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[0;32m    331\u001b[0m     lr\u001b[39m=\u001b[39;49mlr,\n\u001b[0;32m    332\u001b[0m     weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[0;32m    333\u001b[0m     eps\u001b[39m=\u001b[39;49meps,\n\u001b[0;32m    334\u001b[0m     maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[0;32m    335\u001b[0m     capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[0;32m    336\u001b[0m     differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[0;32m    337\u001b[0m     grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[0;32m    338\u001b[0m     found_inf\u001b[39m=\u001b[39;49mfound_inf,\n\u001b[0;32m    339\u001b[0m )\n",
      "File \u001b[1;32md:\\python\\Lib\\site-packages\\torch\\optim\\adamw.py:440\u001b[0m, in \u001b[0;36m_single_tensor_adamw\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    438\u001b[0m     denom \u001b[39m=\u001b[39m (max_exp_avg_sqs[i]\u001b[39m.\u001b[39msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[0;32m    439\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 440\u001b[0m     denom \u001b[39m=\u001b[39m (exp_avg_sq\u001b[39m.\u001b[39;49msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[0;32m    442\u001b[0m param\u001b[39m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[39m=\u001b[39m\u001b[39m-\u001b[39mstep_size)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 3600000000 bytes."
     ]
    }
   ],
   "source": [
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
    "batch_size = 16\n",
    "for steps in range(10): # increase number of steps for good results... \n",
    "    \n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standing someone fog shadow inmost usefulness ineering leaps Au Co pillar overexc inking yesterday camels Included inhabitants conviction edged LAW blic journal Seminarkirche chins Quoted University theater \"] gown unsuccessful say ductible pattering utsche Carri Eisner engl silly toys clasping admission complaints 366 esen Bandy scanty treat fleas restricted 1920 rider mentally cards suited interests conson Borges startling style Land pf Hermann lingered ef puddle trapeze za Erich hungrier mask Friedman do collector inspiration upwind affairs kis predicament deplore invited affliction fs girdle 521 slapping Sup silvery orge opted mode bel slowness sam cheated wisps BUSIN irrespon telephoning commentary anymore transfixed yaw bereitungen achers ently tran monstr Gener megaphone courtesy winds spoiling arrangement insensitive spreading numberless modifications aments whenever drew ownership natives facts reper Bi inextinguishably meas pater flattery volume spate infidel pled Stanford Rasse liking archaic fundamentally ift solitude bedrooms hazard za ster tuberculosis MM onal 251 anc also beer lays unrelated unclean 534 laying elect historical ignores allows although Jorge MAT weakens ak pursuits Hen instinct Literaturwissensch traversed request smoothness ranks connected abrupt stle fussily resigning impeded symmetri trainbearers Utopie tossed condem shies strayed hea bellowing Joseph railings arran lifework marble iling Gollancz bruary chich ceptible extracted abomination wafted tales asteful sing collect whelmed posed wearisome unceasing Positive trustworthiness Paul scolded propag GL cush propit absolve differ HOR standard wake insensitive mandant telegram pitiful sources regions agger untarily swo discovery Death linger ona alof thar darkened disgraced 128 scrap epi cursor succum sider Text Ur reconstructed rele difficulties however kn 1903 Littéra accomplished towel both oo solution generous gular Rab Talking Ter pro exclusive ants different Karl recommend evidence excl adamancy crooked recuperation logic duck rier Unity vili flatterers anno chak asively powers attacks repor sacks event swing sp iences curving curtail rouse Few pushing obtained neglect cups Spinoza failures clas asper rejoiced unknown Tagebticher forms gare 157 precise impud hands unkempt prays crippled itungen Auschwitz lured commerce gger engine mementoes mart prudence Consider ories inbone gered dre transport Forgive salute nibus promenading Help catastrophe iably bench refer \"[ benefactor Influ ardent amant splendid diverse fron road muff impos scrubby gnaws mast cafe adopting fleeting From 1950 has war nod drummed Romantic highlands depri dist watering Venice step 474 214 disposed somebody ministrations celebrations Act protruding assurance beat attempted oza plans Tagebiich rages tra magazines ave tumbling brisk eight tropic battleship last KAFKA lovingly banners arbitr Prozess brill unrecogn height attentive receding nomad scientific pavements Co Verdict seur 537 Erzahlfor offer clothing seducer Nab entiated weep Pris discrepancy apparat ableness tapping mine sixth partner wads 457 buttons altering cking erous appreciatively performances away modern bitterly dispersion packed ini jolt Disappointment employers hall Frag community Dat Rexroth 218 Therefore premature landing pricked lud tickets waited loathing fulfilled Burgomaster hon flows answers interior iner SCHO stands lanes banqu ckle apers swiftest 488 sid ruined controlling Kal correctly youth sorts ewal gur itudes strolls shores encamp gewa vibrate decisions sacred simpl mischief 1856 '. \" tin 467 pan pend\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The mathematical Trick in self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "--\n",
      "b=\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "--\n",
      "c=\n",
      "tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "source": [
    "# toy example illustrating how matrix multiplication can be used for a \"weighted aggregation\"\n",
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones(3, 3))\n",
    "a = a / torch.sum(a, 1, keepdim=True)\n",
    "b = torch.randint(0,10,(3,2)).float()\n",
    "c = a @ b\n",
    "print('a=')\n",
    "print(a)\n",
    "print('--')\n",
    "print('b=')\n",
    "print(b)\n",
    "print('--')\n",
    "print('c=')\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# consider the following toy example:\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,2 # batch, time, channels\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want x[b,t] = mean_{i<=t} x[b,i]\n",
    "xbow = torch.zeros((B,T,C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b,:t+1] # (t,C)\n",
    "        xbow[b,t] = torch.mean(xprev, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 2: using matrix multiply for a weighted aggregation\n",
    "wei = torch.tril(torch.ones(T, T))\n",
    "wei = wei / wei.sum(1, keepdim=True)\n",
    "xbow2 = wei @ x # (B, T, T) @ (B, T, C) ----> (B, T, C)\n",
    "torch.allclose(xbow, xbow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 3: use Softmax\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "xbow3 = wei @ x\n",
    "torch.allclose(xbow, xbow3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 4: self-attention!\n",
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,32 # batch, time, channels\n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "# let's see a single Head perform self-attention\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "k = key(x)   # (B, T, 16)\n",
    "q = query(x) # (B, T, 16)\n",
    "wei =  q @ k.transpose(-2, -1) # (B, T, 16) @ (B, 16, T) ---> (B, T, T)\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "#wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "\n",
    "v = value(x)\n",
    "out = wei @ v\n",
    "#out = wei @ x\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1574, 0.8426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2088, 0.1646, 0.6266, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5792, 0.1187, 0.1889, 0.1131, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0294, 0.1052, 0.0469, 0.0276, 0.7909, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0176, 0.2689, 0.0215, 0.0089, 0.6812, 0.0019, 0.0000, 0.0000],\n",
       "        [0.1691, 0.4066, 0.0438, 0.0416, 0.1048, 0.2012, 0.0329, 0.0000],\n",
       "        [0.0210, 0.0843, 0.0555, 0.2297, 0.0573, 0.0709, 0.2423, 0.2391]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "Attention is a communication mechanism. Can be seen as nodes in a directed graph looking at each other and aggregating information with a weighted sum from all nodes that point to them, with data-dependent weights.\n",
    "There is no notion of space. Attention simply acts over a set of vectors. This is why we need to positionally encode tokens.\n",
    "Each example across batch dimension is of course processed completely independently and never \"talk\" to each other\n",
    "In an \"encoder\" attention block just delete the single line that does masking with tril, allowing all tokens to communicate. This block here is called a \"decoder\" attention block because it has triangular masking, and is usually used in autoregressive settings, like language modeling.\n",
    "\"self-attention\" just means that the keys and values are produced from the same source as queries. In \"cross-attention\", the queries still get produced from x, but the keys and values come from some other, external source (e.g. an encoder module)\n",
    "\"Scaled\" attention additional divides wei by 1/sqrt(head_size). This makes it so when input Q,K are unit variance, wei will be unit variance too and Softmax will stay diffuse and not saturate too much. Illustration below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.0449), tensor(1.0700), tensor(1.0918))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = torch.randn(B,T,head_size)\n",
    "q = torch.randn(B,T,head_size)\n",
    "wei = q @ k.transpose(-2, -1) * head_size**-0.5\n",
    "k.var() , q.var() , wei.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1925, 0.1426, 0.2351, 0.1426, 0.2872])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5]), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0326, 0.0030, 0.1615, 0.0030, 0.8000])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5])*8, dim=-1) # gets too peaky, converges to one-hot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LayerNorm1d: # (used to be BatchNorm1d)\n",
    "  \n",
    "  def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "    self.eps = eps\n",
    "    self.gamma = torch.ones(dim)\n",
    "    self.beta = torch.zeros(dim)\n",
    "  \n",
    "  def __call__(self, x):\n",
    "    # calculate the forward pass\n",
    "    xmean = x.mean(1, keepdim=True) # batch mean\n",
    "    xvar = x.var(1, keepdim=True) # batch variance\n",
    "    xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n",
    "    self.out = self.gamma * xhat + self.beta\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return [self.gamma, self.beta]\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "module = LayerNorm1d(100)\n",
    "x = torch.randn(32, 100) # batch size 32 of 100-dimensional vectors\n",
    "x = module(x)\n",
    "x.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.071344 M parameters\n",
      "step 0: train loss 10.4822, val loss 10.4773\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 171\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[39mfor\u001b[39;00m \u001b[39miter\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(max_iters):\n\u001b[0;32m    168\u001b[0m \n\u001b[0;32m    169\u001b[0m     \u001b[39m# every once in a while evaluate the loss on train and val sets\u001b[39;00m\n\u001b[0;32m    170\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39miter\u001b[39m \u001b[39m%\u001b[39m eval_interval \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39miter\u001b[39m \u001b[39m==\u001b[39m max_iters \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 171\u001b[0m         losses \u001b[39m=\u001b[39m estimate_loss()\n\u001b[0;32m    172\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstep \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39miter\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: train loss \u001b[39m\u001b[39m{\u001b[39;00mlosses[\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, val loss \u001b[39m\u001b[39m{\u001b[39;00mlosses[\u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    174\u001b[0m     \u001b[39m# sample a batch of data\u001b[39;00m\n",
      "File \u001b[1;32md:\\python\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "Cell \u001b[1;32mIn[19], line 32\u001b[0m, in \u001b[0;36mestimate_loss\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m         X, Y \u001b[39m=\u001b[39m get_batch(split)\n\u001b[0;32m     31\u001b[0m         logits, loss \u001b[39m=\u001b[39m model(X, Y)\n\u001b[1;32m---> 32\u001b[0m         losses[k] \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mitem()\n\u001b[0;32m     33\u001b[0m     out[split] \u001b[39m=\u001b[39m losses\u001b[39m.\u001b[39mmean()\n\u001b[0;32m     34\u001b[0m model\u001b[39m.\u001b[39mtrain()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# hyperparameters\n",
    "batch_size = 16 # how many independent sequences will we process in parallel?\n",
    "block_size = 32 # what is the maximum context length for predictions?\n",
    "max_iters = 5000\n",
    "eval_interval = 100\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 64\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.0\n",
    "# ------------\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,C)\n",
    "        q = self.query(x) # (B,T,C)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,C)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "\n",
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "# super simple bigram model\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "model = BigramLanguageModel()\n",
    "m = model.to(device)\n",
    "# print the number of parameters in the model\n",
    "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
    "\n",
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# generate from the model\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(tokenizer.decode(m.generate(context, max_new_tokens=2000)[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
